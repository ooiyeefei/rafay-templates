# These values are for the official, independent Ollama chart.

# --- Common Settings (Applied Always) ---
# We always want persistence for a stateful service like Ollama.
persistence:
  enabled: true
  storageClass: "gp3"
  size: 50Gi

# We only add the models block if the list is not empty.
%{ if length(ollama_models) > 0 ~}
models:
%{ for model in ollama_models ~}
  - name: "${model}"
%{ endfor ~}
%{ endif ~}


# --- GPU-Specific Settings ---
# This block is now ONLY rendered if 'ollama_on_gpu' is true.
%{ if ollama_on_gpu ~}
nodeSelector:
  accelerator: "nvidia"

tolerations:
  - key: "nvidia.com/gpu"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"

resources:
  limits:
    nvidia.com/gpu: 1
%{ endif ~}